1. Create a standard analyzer
2. Create a simple analyzer
3. Create a  whitespace analyzer
4. Create a language analyzer
5. Create a multi analyzer
6. Create a Analyzer with tokenzier

POST _analyze
{
  "analyzer": "standard",
  "text": "THE 3 QUICK Brown-Foxes jumped over the neighbouts fence"
}

Notes:
1.It will split into tokenizer,numbers will be defined as NUM and words will be defined
by the the type ALPHANUM
2.converts into the lower case

output

  "tokens": [
    {
      "token": "the",
      "start_offset": 0,
      "end_offset": 3,
      "type": "<ALPHANUM>",
      "position": 0
    },
    {
      "token": "3",
      "start_offset": 4,
      "end_offset": 5,
      "type": "<NUM>",
      "position": 1
    },
    {
      "token": "quick",
      "start_offset": 6,
      "end_offset": 11,
      "type": "<ALPHANUM>",
      "position": 2
    },
    {
      "token": "brown",
      "start_offset": 12,
      "end_offset": 17,
      "type": "<ALPHANUM>",
      "position": 3
    },
    {
      "token": "foxes",
      "start_offset": 18,
      "end_offset": 23,
      "type": "<ALPHANUM>",
      "position": 4
    },
    {
      "token": "jumped",
      "start_offset": 24,
      "end_offset": 30,
      "type": "<ALPHANUM>",
      "position": 5
    },
    {
      "token": "over",
      "start_offset": 31,
      "end_offset": 35,
      "type": "<ALPHANUM>",
      "position": 6
    },
    {
      "token": "the",
      "start_offset": 36,
      "end_offset": 39,
      "type": "<ALPHANUM>",
      "position": 7
    },
    {
      "token": "neighbouts",
      "start_offset": 40,
      "end_offset": 50,
      "type": "<ALPHANUM>",
      "position": 8
    },
    {
      "token": "fence",
      "start_offset": 51,
      "end_offset": 56,
      "type": "<ALPHANUM>",
      "position": 9
    }
  ]
}

2.
Simple Analyzer
It will be split based on the '

POST _analyze
{
  "analyzer": "simple",
  "text": "THE 3 QUICK Brown-Foxes jumped over the neighbour's fence"
}


3. Create a whitespace Analyzer
POST _analyze
{
  "analyzer": "whitespace",
  "text": "THE 3 QUICK Brown-Foxes jumped over the neighbour's fence"
}

Note:
It will split based on the whitespace.
While searching the with whitespace Analyzer , the pattern must be exact.


4.POST _analyze
{
  "analyzer": "english",
  "text": "THE 3 QUICK Brown-Foxes jumped over the neighbour's fence"
}

Notes:
It will remove all the stop words and remove all the hypens, single quotes..etc
IT will remove the root words like fox instead foxes

5. Create a multi-analyzer
---------------------------
step a:
PUT index-18
{
  "mappings": {
    "doc": {
      "properties": {
        "text": {
          "type": "text",
          "fields": {
            "simple": {
              "type": "text",
              "analyzer": "simple"
            },
            "whitespace": {
              "type": "text",
              "analyzer": "whitespace"
            },
            "english": {
              "type": "text",
              "analyzer": "english"
            }
          }
        }
      }
    }
  }
}

step b:
PUT index-18/doc/1
{
 "text": "THE 3 QUICK Brown-Foxes jumped over the neighbour's fence"
}

step c:
GET index-18/_search
{
  "query": {
    "match": {
      "text.simple": "neighbour's"
    }
  }
 }
 
6.
PUT index-19
{
  "mappings": {
    "doc": {
      "properties": {
        "text": {
          "type": "text",
          "analyzer": "whitespace_lowercase"
        }
      }
    }
  },
  "settings": {
    "analysis": {
      "analyzer": {
        "whitespace_lowercase": {
          "tokenizer": "whitespace",
          "filter": [
            "lowercase"
          ]
        }
      }
    }
  }
}

Note: 
First we need to create a settings part and use that one as the Analyzer

